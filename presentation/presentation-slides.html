<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>File Organization &amp; Data Cleaning in R</title>
    <meta charset="utf-8" />
    <meta name="author" content="Isabella Richmond" />
    <script src="libs/header-attrs-2.8/header-attrs.js"></script>
    <link href="libs/remark-css-0.0.1/metropolis.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/metropolis-fonts.css" rel="stylesheet" />
    <link rel="stylesheet" href="extras-slides.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# File Organization &amp; Data Cleaning in R
### Isabella Richmond
### October 12, 2021 [updated: October 11 2021]

---


# What we are learning today &amp; why 
- Everyone wants to learn about file organization and data cleaning/processing! So here we go! 

&lt;img src="google1.png" width="1047" /&gt;

---
# What we are learning today &amp; why 
- Everyone wants to learn about file organization and data cleaning/processing! So here we go! 

&lt;img src="google2.png" width="1047" /&gt;


---
# A couple notes
- Data archiving in the Ziter lab 
  - We do have a place and and specific formatting requirements for data archiving - we can discuss this more later but this exists (reach out if this is something you want to do in the next couple of weeks)
  
&lt;img src="righttool.PNG" width="730" /&gt;
.footnote[
[1]: [Scientific Computing](https://sciencecomputing.io)
]


---
class: important
# Part 1: Data &amp; File Organization  
## [Tidy Data](https://www.jstatsoft.org/article/view/v059i10) 
- Tidy data is a framework for how data should be formatted for easy and efficient data cleaning created by [Hadley Wickham](http://hadley.nz/)
  - These principles are the underpinnings of `tidyverse` packages (e.g. ggplot2)   


## Principles 
1. Each variable forms a column
2. Each observation forms a row 
2. Each type of observational unit forms a table

---
class: important 

# Part 1: Data &amp; File Organization  
## Tidy Data 
- The best way to start data/file organization is to use best practices in data collection/spreadsheet formatting 
- There are some really [common spreadsheet errors](https://datacarpentry.org/spreadsheet-ecology-lesson/02-common-mistakes/index.html) that ecologists often use when collecting data 
- We are not going to format a spreadsheet today, but I'd encourage you to take a look at that link and incorporate suggestions next time you're collecting/inputting data


---
class: important 
# Part 1: Data &amp; File Organization 
Good file structure is important because it: 
- Ensures the integrity of your data 
- Makes it easier to share your code with people 
- Makes it easier to upload your code/data with manuscript submission 
- Makes it easier to come back after a break 

Best practices include (but are not limited to): 
- Use an R Project file so that your project is easily shareable
- Always treat raw data as read-only
- Store cleaned data in a separate folder (or distinguish clearly)
- Treat output as disposable - you should always be able to re-generate with script
- Have separate function and figure scripts

.footnote[
[1]: [Software Carpentry Project Management](https://swcarpentry.github.io/r-novice-gapminder/02-project-intro/index.html)
]

---
class: important 

# Part 1: Data &amp; File Organization

This is how I set up my file structure with my R Projects. If you want more examples, most of my repositories on [GitHub](https://github.com/icrichmond/) are set up in in the same (or very similar manner): 

&lt;img src="filestructure.png" width="1833" /&gt;

---
class: important 

# Part 1: Data &amp; File Organization

This is how I set up my file structure with my R Projects. If you want more examples, most of my repositories on [GitHub](https://github.com/icrichmond/) are set up in in the same (or very similar manner): 

&lt;img src="filestructure2.png" width="1831" /&gt;

---
class: review
# Part 2: File Organization Practice 
All together now! 
- We are going to download messy and unstructured GitHub folder from [here](https://github.com/icrichmond/ZULE-data-cleaning-workshop) &amp; unzip 
- Then we are going to set up an R project &amp; the file structure we just talked about  





Ok... Moving on to cleaning data in R! 

---
class: important 
# Part 3: Cleaning Data in R 
Some reasons why I clean my data in R (use the tool that works for you)
1. Reproducible 
2. Open-source and cross-platform
3. Reliable &amp; clear 
4. High-quality graphics
5. Great community &amp; resources
6. Scales with datasets
7. Steep learning curve with a high payoff 

.footnote[
[1]: [Data Carpentry Data Analysis &amp; Visualiation in R for Ecologists](https://datacarpentry.org/R-ecology-lesson/00-before-we-start.html)
]

---
class: important
# Part 3: Cleaning Data in R 
Two big "ecosystems" for data cleaning in R 
.pull-left[
## `tidyverse`
- makes functions corresponding to the most common operations 
- "do one thing at a time approach" 
- chain together multiple things to make a easily understood group of operations 
- many dependencies 
]

.pull-right[
## `data.table`
- provides a high performance version of base R 
- no dependencies 
- complex syntax (I think) but it is very powerful once understood and can make your code extremely efficient by combining many operations and minimizing copying data, freeing up memory

]  

.footnote[
[1]: [tidyverse ](https://www.tidyverse.org/)
[2]: [data.table ](https://rdatatable.gitlab.io/data.table/)
[3]: [Comparison of tidyverse and data.table](https://atrebas.github.io/post/2019-03-03-datatable-dplyr/)
]
---
class: review
# Part 4: Practice cleaning messy Data in R
I have created a spreadsheet that integrates MANY of the common problems in datasets... We are going to go through step by step and clean this dataset so it is ready for analysis.   



**NOTE:** code is provided using both tidyverse and data.table philosophies in this workshop. Feel free to choose whichever one makes sense to you in the future (or mix &amp; match!). Providing multiple ways to do everything was meant to give you options, not confuse you  


**NOTE 2:** this code assumes you set up your files in an R project with the datasheet in an `input/` folder


---
class: review
# Part 4: Practice cleaning messy Data in R

## Problem: Importing Data   

`tidyverse`

```r
# initial import
tdf &lt;- read_csv("input/example-data.csv")
# read_csv doesn't recognize that the file is delimited using ";" instead of ",". Let's use read_delim to fix that
tdf &lt;- read_delim("input/example-data.csv", delim = ";")
# we still have the problem that the first 8 lines need to be removed for this to be functional 
tdf &lt;- read_delim("input/example-data.csv", delim = ";", skip = 8)
```


`data.table`

```r
# initial import using data.table 
dtdf &lt;- fread("input/example-data.csv")
# fread doesn't recognize that the file is delimited using ";" instead of ",". Let's add it to the data.table argument 
dtdf &lt;- fread("input/example-data.csv", sep = ";")
# we still have the problem that the first 8 lines in data.table need to be removed for this to be functional 
dtdf &lt;- fread("input/example-data.csv", sep = ";", skip = 8)
```



---
class: review
# Part 4: Practice cleaning messy Data in R

## Problem: Special Characters &amp; UTF-8 Encoding 

What would life in Québec be without special characters! When we investigate our tidyverse dataframe, we see an issue with "Montréal". This issue often arises with accents and other special characters, when the dataframe is not properly read as UTF-8

`tidyverse`

```r
# tidyverse can be re-encoded to UTF-8 after import 
tdf$City &lt;- enc2utf8(as(tdf$City, "character"))
```


`data.table`

```r
# data.table incorporates it into the import line 
dtdf &lt;- fread("input/example-data.csv", sep = ";", skip = 8, encoding = "UTF-8") 
```


---
class: review
# Part 4: Practice cleaning messy Data in R

## Problem: NAs &amp; Associated Values

There are often NAs in our datasets, which we may or may not want to keep often, there are also other values that count, biologically, as NAs but are not read into R automatically as NAs. For example, blanks, "NA" (instead of a true NA), zeroes (for some variables), etc.  
`tidyverse`

```r
# Strategy A: When importing (for tidyverse only)
tdf &lt;- read_delim("input/example-data.csv", delim = ";", skip = 8, na = c(""," ", "NA", 0, "0"))
# Strategy B: After importing
tdf$DBH &lt;- na_if(tdf$DBH, 0)
# Drop the NAs
tdf &lt;- drop_na(tdf)
```


`data.table`

```r
# Strategy B: After importing
dtdf$DBH[dtdf$DBH == 0] &lt;- NA 
# Drop the NAs
dtdf &lt;- na.omit(dtdf)
```


---
class: review
# Part 4: Practice cleaning messy Data in R

## Problem: Duplicates

Sometimes, there are duplicate observations/rows in datasets. These can really mess up your analysis if you don't catch them. Testing your dataset for duplicates and then removing what you find is an important step in data cleaning!  

`tidyverse`

```r
# investigate which lines are duplicates
tdup &lt;- tdf[duplicated(tdf), c("TreeID", "City", "DBH", "Species,")]
# remove duplicates
tdf &lt;- distinct(tdf)
```


`data.table`

```r
# investigate which lines are duplicates
dtdup &lt;- dtdf[duplicated(dtdf), c("TreeID", "City", "DBH", "Species,")]
# remove duplicates 
dtdf &lt;- unique(dtdf)
```

---
class: review
# Part 4: Practice cleaning messy Data in R

## Problem: Column Names

Bad column names can make your life a living hell. Before moving into analysis make sure your column names follow best practices, you'll thank me later! You don't want numbers, special characters, or spaces in your column names. Let's change our really bad column names.  

`tidyverse`

```r
tdf &lt;- rename(tdf, 
              Date = "1st Date Measured",
              Time = "Time  Measured", 
              Species = "Species,")
```


`data.table`

```r
dtdf &lt;- setnames(dtdf,                              
                 c("1st Date Measured", "Time  Measured", "Species,"),
                 c("Date", "Time", "Species"))
```


---
class: review
# Part 4: Practice cleaning messy Data in R

## Problem: Value Formatting - Spelling Mistakes

In our dataset, Toronto is spelled wrong. If you have a huge dataset with many spelling errors, OpenRefine is a great tool to use. For us, our dataset is small and we can visually inspect it for spelling errors so we will replace the error in R.  

`tidyverse`

```r
tdf$City &lt;- recode(tdf$City, Toronno = "Toronto")
```


`data.table`

```r
dtdf$City[dtdf$City %in% c("Toronno", "TO", "The birthplace of Drake")] &lt;- "Toronto"
```


---
class: review
# Part 4: Practice cleaning messy Data in R

## Problem: Value Formatting - Formatting Column Types

City and species are currently formatted as character types, but for our study we want them to act as factors - we need to reclassify them. Its always important to check the classes of your data, R makes assumptions when importing your data and can be wrong!  

`tidyverse`

```r
tdf$City &lt;- as_factor(tdf$City)
tdf$Species &lt;- as_factor(tdf$Species)
```


`data.table`

```r
factor_cols &lt;- c("City", "Species")
dtdf[ ,(factor_cols) := lapply(.SD, as.factor),
      .SDcols = factor_cols]
```


---
class: review
# Part 4: Practice cleaning messy Data in R

## Problem: Value Formatting - Text Parsing
We have a comma at the end of our species names, that we don't really want. We can use text parsing to remove those unwanted commas from the Species column.  

`tidyverse`

```r
tdf$Species &lt;- str_remove(tdf$Species, "[,]") # this will remove a comma anywhere in the column
```


`data.table`

```r
dtdf$Species &lt;- gsub(",","",dtdf$Species)
```


---
class: review
# Part 4: Practice cleaning messy Data in R

## Problem: Date/Time Formatting

Date and time formatting in R can be really tricky and frustrating sometimes but is often really necessary for field data (and other data). `anytime` is a cool package that makes the process a little bit easier. First we want a date-time column, not separate entities   
`tidyverse`

```r
tdf &lt;- unite(tdf, "DateTime", Date:Time, sep = " ")
```

`data.table`

```r
dtdf[,DateTime:=paste0(Date," ",Time)]
dtdf[, c("Date","Time"):=NULL]
```

Now we use anytime to format the columns.
NOTE: Be careful of time zones, anytime will automatically set to where you are. If you are using data from other time zones and need to indicate that, use the `parsedate` package. 

```r
tdf$DateTime &lt;- anytime(tdf$DateTime)
dtdf$DateTime &lt;- anytime(dtdf$DateTime)
```


---
class: review
# Part 4: Practice cleaning messy Data in R

## Problem: Reshaping
Often the way datasets are initially set up are not ideal for things like plotting and modelling (they don't follow tidy data practices). So we need to reshape the dataframe - make it longer or wider - to do what we need to do.  

`tidyverse`

```r
# let's make the dataframe wider - we only want one entry per city 
tdf_wide &lt;- pivot_wider(tdf, names_from = Species, values_from = DBH)
# Hmmmmm that is not the most useful format - let's make it longer again (or melt it)
tdf_long &lt;- pivot_longer(tdf_wide, cols = 4:14, names_to = "Species", values_to = "DBH", values_drop_na = T)
```


`data.table`

```r
# dcast and melt for data.table
dtdf_wide &lt;- dcast(dtdf, formula = City + TreeID + DateTime ~ Species, value.var = "DBH")
dtdf_long &lt;- melt(dtdf_wide, id.vars = c("TreeID","City", "DateTime"), variable.name = "Species", value.name = "DBH", na.rm = T) 
```

---
class: review
# Part 4: Practice cleaning messy Data in R

## Problem: Saving/Exporting Data
Don't forget to save your beautiful, cleaned data! Maybe you have a "cleaned" folder in your input directory, save it there.  
If this is a final product, save it to output.  
If this is an intermediate item, the best way to save it is as an .rds file  
If this is a final product or something you will be sharing, save it as a .csv

`tidyverse`

```r
saveRDS(tdf, "output/TidyData.rds")
write_csv(tdf, "output/TidyData.csv")
```


`data.table`

```r
saveRDS(dtdf, "output/DataTableData.rds")
fwrite(dtdf, "output/DataTableData.csv")
```


---
class: important 
# Resources 
- [data.table in R Guide](https://www.machinelearningplus.com/data-manipulation/datatable-in-r-complete-guide/)
- [R for Reproducible Scientific Analysis](https://swcarpentry.github.io/r-novice-gapminder/)
- [Data Analysis &amp; Visualization in R for Ecologists](https://datacarpentry.org/R-ecology-lesson/index.html)
- [Data Organization in Spreadsheets for Ecologists](https://datacarpentry.org/R-ecology-lesson/index.html)
- [Tidy Data by Hadley Wickham](https://www.jstatsoft.org/article/view/v059i10)
- [Dr. Christie Bahlai's Reproducible Quantitative Methods Course](https://cbahlai.github.io/rqm-template/)
- [Wildlife Ecology &amp; Evolution Lab's Guide by Alec Robitaille](https://weel.gitlab.io/guide/)
- [data.table Website](https://rdatatable.gitlab.io/data.table/)
- [tidyverse Website](https://www.tidyverse.org/)
- [xaringan Website: package I used to make these slides](https://slides.yihui.org/xaringan/#1)
- [OpenRefine](https://openrefine.org/)
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script src="macros-slides.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false,
"slideNumberFormat": "<div class=\"progress-bar-container\">\n  <div class=\"progress-bar\" style=\"width: calc(%current% / %total% * 100%);\">\n  </div>\n</div>`\n"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
